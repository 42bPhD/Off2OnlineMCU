{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import copy\n",
    "from quantization.repvgg_quantized import RepVGGWholeQuant\n",
    "# from quantization.repvgg_quantized import RepVGGWholeQuant\n",
    "from repvggplus import create_RepVGGplus_by_name, repvgg_model_convert\n",
    "import os\n",
    "from torchsummary import summary\n",
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading cifar10 data...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "=================== Building the vanila RepVGG ===================\n",
      "=> loading checkpoint './trained_models/RepVGG-C1/qformat-cifar10/best_ckpt.pth'\n",
      "dict_keys(['stage0.rbr_dense.conv.weight', 'stage0.rbr_dense.conv.input_param.frac_bit', 'stage0.rbr_dense.conv.input_param.min', 'stage0.rbr_dense.conv.input_param.max', 'stage0.rbr_dense.conv.weight_param.frac_bit', 'stage0.rbr_dense.conv.weight_param.min', 'stage0.rbr_dense.conv.weight_param.max', 'stage0.rbr_dense.conv.output_param.frac_bit', 'stage0.rbr_dense.conv.output_param.min', 'stage0.rbr_dense.conv.output_param.max', 'stage0.rbr_dense.bn.weight', 'stage0.rbr_dense.bn.bias', 'stage0.rbr_dense.bn.running_mean', 'stage0.rbr_dense.bn.running_var', 'stage0.rbr_dense.bn.num_batches_tracked', 'stage0.rbr_1x1.conv.weight', 'stage0.rbr_1x1.conv.input_param.frac_bit', 'stage0.rbr_1x1.conv.input_param.min', 'stage0.rbr_1x1.conv.input_param.max', 'stage0.rbr_1x1.conv.weight_param.frac_bit', 'stage0.rbr_1x1.conv.weight_param.min', 'stage0.rbr_1x1.conv.weight_param.max', 'stage0.rbr_1x1.conv.output_param.frac_bit', 'stage0.rbr_1x1.conv.output_param.min', 'stage0.rbr_1x1.conv.output_param.max', 'stage0.rbr_1x1.bn.weight', 'stage0.rbr_1x1.bn.bias', 'stage0.rbr_1x1.bn.running_mean', 'stage0.rbr_1x1.bn.running_var', 'stage0.rbr_1x1.bn.num_batches_tracked', 'stage1.0.rbr_dense.conv.weight', 'stage1.0.rbr_dense.conv.input_param.frac_bit', 'stage1.0.rbr_dense.conv.input_param.min', 'stage1.0.rbr_dense.conv.input_param.max', 'stage1.0.rbr_dense.conv.weight_param.frac_bit', 'stage1.0.rbr_dense.conv.weight_param.min', 'stage1.0.rbr_dense.conv.weight_param.max', 'stage1.0.rbr_dense.conv.output_param.frac_bit', 'stage1.0.rbr_dense.conv.output_param.min', 'stage1.0.rbr_dense.conv.output_param.max', 'stage1.0.rbr_dense.bn.weight', 'stage1.0.rbr_dense.bn.bias', 'stage1.0.rbr_dense.bn.running_mean', 'stage1.0.rbr_dense.bn.running_var', 'stage1.0.rbr_dense.bn.num_batches_tracked', 'stage1.0.rbr_1x1.conv.weight', 'stage1.0.rbr_1x1.conv.input_param.frac_bit', 'stage1.0.rbr_1x1.conv.input_param.min', 'stage1.0.rbr_1x1.conv.input_param.max', 'stage1.0.rbr_1x1.conv.weight_param.frac_bit', 'stage1.0.rbr_1x1.conv.weight_param.min', 'stage1.0.rbr_1x1.conv.weight_param.max', 'stage1.0.rbr_1x1.conv.output_param.frac_bit', 'stage1.0.rbr_1x1.conv.output_param.min', 'stage1.0.rbr_1x1.conv.output_param.max', 'stage1.0.rbr_1x1.bn.weight', 'stage1.0.rbr_1x1.bn.bias', 'stage1.0.rbr_1x1.bn.running_mean', 'stage1.0.rbr_1x1.bn.running_var', 'stage1.0.rbr_1x1.bn.num_batches_tracked', 'stage2.0.rbr_dense.conv.weight', 'stage2.0.rbr_dense.conv.input_param.frac_bit', 'stage2.0.rbr_dense.conv.input_param.min', 'stage2.0.rbr_dense.conv.input_param.max', 'stage2.0.rbr_dense.conv.weight_param.frac_bit', 'stage2.0.rbr_dense.conv.weight_param.min', 'stage2.0.rbr_dense.conv.weight_param.max', 'stage2.0.rbr_dense.conv.output_param.frac_bit', 'stage2.0.rbr_dense.conv.output_param.min', 'stage2.0.rbr_dense.conv.output_param.max', 'stage2.0.rbr_dense.bn.weight', 'stage2.0.rbr_dense.bn.bias', 'stage2.0.rbr_dense.bn.running_mean', 'stage2.0.rbr_dense.bn.running_var', 'stage2.0.rbr_dense.bn.num_batches_tracked', 'stage2.0.rbr_1x1.conv.weight', 'stage2.0.rbr_1x1.conv.input_param.frac_bit', 'stage2.0.rbr_1x1.conv.input_param.min', 'stage2.0.rbr_1x1.conv.input_param.max', 'stage2.0.rbr_1x1.conv.weight_param.frac_bit', 'stage2.0.rbr_1x1.conv.weight_param.min', 'stage2.0.rbr_1x1.conv.weight_param.max', 'stage2.0.rbr_1x1.conv.output_param.frac_bit', 'stage2.0.rbr_1x1.conv.output_param.min', 'stage2.0.rbr_1x1.conv.output_param.max', 'stage2.0.rbr_1x1.bn.weight', 'stage2.0.rbr_1x1.bn.bias', 'stage2.0.rbr_1x1.bn.running_mean', 'stage2.0.rbr_1x1.bn.running_var', 'stage2.0.rbr_1x1.bn.num_batches_tracked', 'stage3.0.rbr_dense.conv.weight', 'stage3.0.rbr_dense.conv.input_param.frac_bit', 'stage3.0.rbr_dense.conv.input_param.min', 'stage3.0.rbr_dense.conv.input_param.max', 'stage3.0.rbr_dense.conv.weight_param.frac_bit', 'stage3.0.rbr_dense.conv.weight_param.min', 'stage3.0.rbr_dense.conv.weight_param.max', 'stage3.0.rbr_dense.conv.output_param.frac_bit', 'stage3.0.rbr_dense.conv.output_param.min', 'stage3.0.rbr_dense.conv.output_param.max', 'stage3.0.rbr_dense.bn.weight', 'stage3.0.rbr_dense.bn.bias', 'stage3.0.rbr_dense.bn.running_mean', 'stage3.0.rbr_dense.bn.running_var', 'stage3.0.rbr_dense.bn.num_batches_tracked', 'stage3.0.rbr_1x1.conv.weight', 'stage3.0.rbr_1x1.conv.input_param.frac_bit', 'stage3.0.rbr_1x1.conv.input_param.min', 'stage3.0.rbr_1x1.conv.input_param.max', 'stage3.0.rbr_1x1.conv.weight_param.frac_bit', 'stage3.0.rbr_1x1.conv.weight_param.min', 'stage3.0.rbr_1x1.conv.weight_param.max', 'stage3.0.rbr_1x1.conv.output_param.frac_bit', 'stage3.0.rbr_1x1.conv.output_param.min', 'stage3.0.rbr_1x1.conv.output_param.max', 'stage3.0.rbr_1x1.bn.weight', 'stage3.0.rbr_1x1.bn.bias', 'stage3.0.rbr_1x1.bn.running_mean', 'stage3.0.rbr_1x1.bn.running_var', 'stage3.0.rbr_1x1.bn.num_batches_tracked', 'stage4.0.rbr_dense.conv.weight', 'stage4.0.rbr_dense.conv.input_param.frac_bit', 'stage4.0.rbr_dense.conv.input_param.min', 'stage4.0.rbr_dense.conv.input_param.max', 'stage4.0.rbr_dense.conv.weight_param.frac_bit', 'stage4.0.rbr_dense.conv.weight_param.min', 'stage4.0.rbr_dense.conv.weight_param.max', 'stage4.0.rbr_dense.conv.output_param.frac_bit', 'stage4.0.rbr_dense.conv.output_param.min', 'stage4.0.rbr_dense.conv.output_param.max', 'stage4.0.rbr_dense.bn.weight', 'stage4.0.rbr_dense.bn.bias', 'stage4.0.rbr_dense.bn.running_mean', 'stage4.0.rbr_dense.bn.running_var', 'stage4.0.rbr_dense.bn.num_batches_tracked', 'stage4.0.rbr_1x1.conv.weight', 'stage4.0.rbr_1x1.conv.input_param.frac_bit', 'stage4.0.rbr_1x1.conv.input_param.min', 'stage4.0.rbr_1x1.conv.input_param.max', 'stage4.0.rbr_1x1.conv.weight_param.frac_bit', 'stage4.0.rbr_1x1.conv.weight_param.min', 'stage4.0.rbr_1x1.conv.weight_param.max', 'stage4.0.rbr_1x1.conv.output_param.frac_bit', 'stage4.0.rbr_1x1.conv.output_param.min', 'stage4.0.rbr_1x1.conv.output_param.max', 'stage4.0.rbr_1x1.bn.weight', 'stage4.0.rbr_1x1.bn.bias', 'stage4.0.rbr_1x1.bn.running_mean', 'stage4.0.rbr_1x1.bn.running_var', 'stage4.0.rbr_1x1.bn.num_batches_tracked', 'linear.weight', 'linear.bias', 'linear.input_param.frac_bit', 'linear.input_param.min', 'linear.input_param.max', 'linear.weight_param.frac_bit', 'linear.weight_param.min', 'linear.weight_param.max', 'linear.bias_param.frac_bit', 'linear.bias_param.min', 'linear.bias_param.max', 'linear.output_param.frac_bit', 'linear.output_param.min', 'linear.output_param.max'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "77.98999786376953"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from RepOptimizers.data.dataloader import get_dataloader, get_subnet_dataloader\n",
    "data_dir = \"E:/1_TinyML/tiny/benchmark/training/visual_wake_words/vw_coco2014_96\"\n",
    "image_size = 32\n",
    "workers = 4\n",
    "batch_size = 128\n",
    "from main import get_cifar10_loader\n",
    "# val_loader = get_subnet_dataloader(data_dir, subset_len=1000, batch_size=batch_size, image_size=image_size, num_workers=workers)\n",
    "_, val_loader = get_cifar10_loader(batchsize=batch_size, image_size=image_size, num_workers=workers)\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "@torch.no_grad()\n",
    "def get_accuracy(\n",
    "  model,\n",
    "  dataloader,\n",
    "  extra_preprocess = None\n",
    ") -> float:\n",
    "  from tqdm import tqdm\n",
    "  model.eval()\n",
    "\n",
    "  num_samples = 0\n",
    "  num_correct = 0\n",
    "\n",
    "  for inputs, targets in tqdm(dataloader, desc=\"eval\", leave=False):\n",
    "    # Move the data from CPU to GPU\n",
    "    inputs = inputs.cuda()\n",
    "    if extra_preprocess is not None:\n",
    "        for preprocess in extra_preprocess:\n",
    "            inputs = preprocess(inputs)\n",
    "\n",
    "    targets = targets.cuda()\n",
    "\n",
    "    # Inference\n",
    "    outputs = model(inputs)\n",
    "\n",
    "    # Convert logits to class indices\n",
    "    outputs = outputs.argmax(dim=1)\n",
    "\n",
    "    # Update metrics\n",
    "    num_samples += targets.size(0)\n",
    "    num_correct += (outputs == targets).sum()\n",
    "\n",
    "  return (num_correct / num_samples * 100).item()\n",
    "\n",
    "@dataclass\n",
    "class ArgumentParser():\n",
    "    load: str = './trained_models/RepVGG-C1/qformat-cifar10/best_ckpt.pth'\n",
    "    save: str = \"./trained_models/RepVGG-C1/qformat-cifar10/best_ckpt_deploy.pth\"\n",
    "    arch: str = 'RepVGG-C1'\n",
    "\n",
    "args = ArgumentParser()\n",
    "train_model = create_RepVGGplus_by_name(args.arch, deploy=False, num_classes=10)\n",
    "\n",
    "\n",
    "if os.path.isfile(args.load):\n",
    "    print(\"=> loading checkpoint '{}'\".format(args.load))\n",
    "    checkpoint = torch.load(args.load)\n",
    "    if 'state_dict' in checkpoint:\n",
    "        checkpoint = checkpoint['state_dict']\n",
    "    elif 'model' in checkpoint:\n",
    "        checkpoint = checkpoint['model']\n",
    "    ckpt = {k.replace('module.', ''): v for k, v in checkpoint.items()}  # strip the names\n",
    "    print(ckpt.keys())\n",
    "    train_model.load_state_dict(ckpt)\n",
    "else:\n",
    "    print(\"=> no checkpoint found at '{}'\".format(args.load))\n",
    "\n",
    "if 'plus' in args.arch:\n",
    "    train_model.switch_repvggplus_to_deploy()\n",
    "    torch.save(train_model.state_dict(), args.save)\n",
    "else:\n",
    "    pass\n",
    "    train_model = repvgg_model_convert(train_model, save_path=args.save)\n",
    "    \n",
    "    \n",
    "test_input = torch.randn(1, 3, 32, 32)\n",
    "train_model(test_input)\n",
    "train_model = train_model.to(device)\n",
    "get_accuracy(train_model, val_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           QConv2d-1           [-1, 16, 16, 16]             448\n",
      "          Identity-2           [-1, 16, 16, 16]               0\n",
      " HistogramObserver-3           [-1, 16, 16, 16]               0\n",
      "             ReLU6-4           [-1, 16, 16, 16]               0\n",
      "       RepVGGBlock-5           [-1, 16, 16, 16]               0\n",
      "           QConv2d-6             [-1, 16, 8, 8]           2,320\n",
      "          Identity-7             [-1, 16, 8, 8]               0\n",
      " HistogramObserver-8             [-1, 16, 8, 8]               0\n",
      "             ReLU6-9             [-1, 16, 8, 8]               0\n",
      "      RepVGGBlock-10             [-1, 16, 8, 8]               0\n",
      "          QConv2d-11             [-1, 32, 4, 4]           4,640\n",
      "         Identity-12             [-1, 32, 4, 4]               0\n",
      "HistogramObserver-13             [-1, 32, 4, 4]               0\n",
      "            ReLU6-14             [-1, 32, 4, 4]               0\n",
      "      RepVGGBlock-15             [-1, 32, 4, 4]               0\n",
      "          QConv2d-16             [-1, 64, 2, 2]          18,496\n",
      "         Identity-17             [-1, 64, 2, 2]               0\n",
      "HistogramObserver-18             [-1, 64, 2, 2]               0\n",
      "            ReLU6-19             [-1, 64, 2, 2]               0\n",
      "      RepVGGBlock-20             [-1, 64, 2, 2]               0\n",
      "          QConv2d-21            [-1, 128, 1, 1]          73,856\n",
      "         Identity-22            [-1, 128, 1, 1]               0\n",
      "HistogramObserver-23            [-1, 128, 1, 1]               0\n",
      "            ReLU6-24            [-1, 128, 1, 1]               0\n",
      "      RepVGGBlock-25            [-1, 128, 1, 1]               0\n",
      "AdaptiveAvgPool2d-26            [-1, 128, 1, 1]               0\n",
      "          Flatten-27                  [-1, 128]               0\n",
      "          QLinear-28                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 101,050\n",
      "Trainable params: 101,050\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.23\n",
      "Params size (MB): 0.39\n",
      "Estimated Total Size (MB): 0.63\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(train_model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hci-lab01\\.conda\\envs\\lab\\lib\\site-packages\\torch\\ao\\quantization\\observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "q_model = RepVGGWholeQuant(train_model, quantlayers='all')\n",
    "q_model.eval()\n",
    "q_model.prepare_quant()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.3001, -0.3451,  0.7035,  0.2870, -0.2233, -0.4190,  0.8211,  0.1885,\n",
       "         -0.8911, -0.6228]], device='cuda:0', grad_fn=<FakeQuantizeBackward>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_input = torch.randn(1, 3, 96, 96).to(device)\n",
    "q_model.to(device)\n",
    "q_model(test_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RepVGGWholeQuant(\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): HistogramObserver(min_val=-4.03135347366333, max_val=3.9394402503967285)\n",
       "  )\n",
       "  (stage0): RepVGGBlock(\n",
       "    (rbr_reparam): QConv2d(\n",
       "      3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
       "      (input_param): QParam()\n",
       "      (weight_param): QParam()\n",
       "      (bias_param): QParam()\n",
       "      (output_param): QParam()\n",
       "    )\n",
       "    (nonlinearity): ReLU6(\n",
       "      (activation_post_process): HistogramObserver(min_val=0.0, max_val=6.0)\n",
       "    )\n",
       "    (se): Identity()\n",
       "  )\n",
       "  (stage1): Sequential(\n",
       "    (0): RepVGGBlock(\n",
       "      (rbr_reparam): QConv2d(\n",
       "        16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
       "        (input_param): QParam()\n",
       "        (weight_param): QParam()\n",
       "        (bias_param): QParam()\n",
       "        (output_param): QParam()\n",
       "      )\n",
       "      (nonlinearity): ReLU6(\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=6.0)\n",
       "      )\n",
       "      (se): Identity()\n",
       "    )\n",
       "  )\n",
       "  (stage2): Sequential(\n",
       "    (0): RepVGGBlock(\n",
       "      (rbr_reparam): QConv2d(\n",
       "        16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
       "        (input_param): QParam()\n",
       "        (weight_param): QParam()\n",
       "        (bias_param): QParam()\n",
       "        (output_param): QParam()\n",
       "      )\n",
       "      (nonlinearity): ReLU6(\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=6.031355857849121)\n",
       "      )\n",
       "      (se): Identity()\n",
       "    )\n",
       "  )\n",
       "  (stage3): Sequential(\n",
       "    (0): RepVGGBlock(\n",
       "      (rbr_reparam): QConv2d(\n",
       "        32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
       "        (input_param): QParam()\n",
       "        (weight_param): QParam()\n",
       "        (bias_param): QParam()\n",
       "        (output_param): QParam()\n",
       "      )\n",
       "      (nonlinearity): ReLU6(\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=6.031876087188721)\n",
       "      )\n",
       "      (se): Identity()\n",
       "    )\n",
       "  )\n",
       "  (stage4): Sequential(\n",
       "    (0): RepVGGBlock(\n",
       "      (rbr_reparam): QConv2d(\n",
       "        64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
       "        (input_param): QParam()\n",
       "        (weight_param): QParam()\n",
       "        (bias_param): QParam()\n",
       "        (output_param): QParam()\n",
       "      )\n",
       "      (nonlinearity): ReLU6(\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=6.01513671875)\n",
       "      )\n",
       "      (se): Identity()\n",
       "    )\n",
       "  )\n",
       "  (gap): AdaptiveAvgPool2d(output_size=1)\n",
       "  (linear): QLinear(\n",
       "    in_features=128, out_features=10, bias=True\n",
       "    (input_param): QParam()\n",
       "    (weight_param): QParam()\n",
       "    (bias_param): QParam()\n",
       "    (output_param): QParam()\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "qmodel = q_model.to(device)\n",
    "\n",
    "#Calibrate the model\n",
    "cnt = 0\n",
    "with torch.no_grad():\n",
    "  for img, label in val_loader:\n",
    "    img = img.to(device)\n",
    "    label = label.to(device)\n",
    "    if cnt > 10:\n",
    "        break\n",
    "    cnt += 1\n",
    "    qmodel(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "77.98999786376953"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_accuracy(qmodel, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RepVGGWholeQuant(\n",
       "  (quant): QuantStub(\n",
       "    (activation_post_process): HistogramObserver(min_val=-3.6263318061828613, max_val=3.9404337406158447)\n",
       "  )\n",
       "  (stage0): RepVGGBlock(\n",
       "    (rbr_reparam): QConv2d(\n",
       "      3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
       "      (input_param): QParam()\n",
       "      (weight_param): QParam()\n",
       "      (bias_param): QParam()\n",
       "      (output_param): QParam()\n",
       "    )\n",
       "    (nonlinearity): ReLU6(\n",
       "      (activation_post_process): HistogramObserver(min_val=0.0, max_val=6.0)\n",
       "    )\n",
       "    (se): Identity()\n",
       "  )\n",
       "  (stage1): Sequential(\n",
       "    (0): RepVGGBlock(\n",
       "      (rbr_reparam): QConv2d(\n",
       "        16, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
       "        (input_param): QParam()\n",
       "        (weight_param): QParam()\n",
       "        (bias_param): QParam()\n",
       "        (output_param): QParam()\n",
       "      )\n",
       "      (nonlinearity): ReLU6(\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=6.0)\n",
       "      )\n",
       "      (se): Identity()\n",
       "    )\n",
       "  )\n",
       "  (stage2): Sequential(\n",
       "    (0): RepVGGBlock(\n",
       "      (rbr_reparam): QConv2d(\n",
       "        16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
       "        (input_param): QParam()\n",
       "        (weight_param): QParam()\n",
       "        (bias_param): QParam()\n",
       "        (output_param): QParam()\n",
       "      )\n",
       "      (nonlinearity): ReLU6(\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=6.031355857849121)\n",
       "      )\n",
       "      (se): Identity()\n",
       "    )\n",
       "  )\n",
       "  (stage3): Sequential(\n",
       "    (0): RepVGGBlock(\n",
       "      (rbr_reparam): QConv2d(\n",
       "        32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
       "        (input_param): QParam()\n",
       "        (weight_param): QParam()\n",
       "        (bias_param): QParam()\n",
       "        (output_param): QParam()\n",
       "      )\n",
       "      (nonlinearity): ReLU6(\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=6.031876087188721)\n",
       "      )\n",
       "      (se): Identity()\n",
       "    )\n",
       "  )\n",
       "  (stage4): Sequential(\n",
       "    (0): RepVGGBlock(\n",
       "      (rbr_reparam): QConv2d(\n",
       "        64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1)\n",
       "        (input_param): QParam()\n",
       "        (weight_param): QParam()\n",
       "        (bias_param): QParam()\n",
       "        (output_param): QParam()\n",
       "      )\n",
       "      (nonlinearity): ReLU6(\n",
       "        (activation_post_process): HistogramObserver(min_val=0.0, max_val=6.01513671875)\n",
       "      )\n",
       "      (se): Identity()\n",
       "    )\n",
       "  )\n",
       "  (gap): AdaptiveAvgPool2d(output_size=1)\n",
       "  (linear): QLinear(\n",
       "    in_features=128, out_features=10, bias=True\n",
       "    (input_param): QParam()\n",
       "    (weight_param): QParam()\n",
       "    (bias_param): QParam()\n",
       "    (output_param): QParam()\n",
       "  )\n",
       "  (dequant): DeQuantStub()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# qmodel = repvgg_model_convert(qmodel, save_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def get_quantized_range(bitwidth):\n",
    "    quantized_max = (1 << (bitwidth - 1)) - 1\n",
    "    quantized_min = -(1 << (bitwidth - 1))\n",
    "    return quantized_min, quantized_max\n",
    "def plot_weight_distribution(model, bitwidth=32):\n",
    "    # bins = (1 << bitwidth) if bitwidth <= 8 else 256\n",
    "    if bitwidth <= 8:\n",
    "        qmin, qmax = get_quantized_range(bitwidth)\n",
    "        bins = np.arange(qmin, qmax + 2)\n",
    "        align = 'left'\n",
    "    else:\n",
    "        bins = 256\n",
    "        align = 'mid'\n",
    "    fig, axes = plt.subplots(3,3, figsize=(10, 6))\n",
    "    axes = axes.ravel()\n",
    "    plot_index = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.dim() > 1:\n",
    "            ax = axes[plot_index]\n",
    "            ax.hist(param.detach().view(-1).cpu(), bins=bins, density=True, \n",
    "                    align=align, color = 'blue', alpha = 0.5,\n",
    "                    edgecolor='black' if bitwidth <= 4 else None)\n",
    "            if bitwidth <= 4:\n",
    "                quantized_min, quantized_max = get_quantized_range(bitwidth)\n",
    "                ax.set_xticks(np.arange(start=quantized_min, stop=quantized_max+1))\n",
    "            ax.set_xlabel(name)\n",
    "            ax.set_ylabel('density')\n",
    "            plot_index += 1\n",
    "    fig.suptitle(f'Histogram of Weights (bitwidth={bitwidth} bits)')\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=0.925)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.00421847, 0.        , 0.        , 0.00421847, 0.        ,\n",
       "        0.        , 0.00421847, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00421847, 0.        , 0.        , 0.        , 0.00421847,\n",
       "        0.        , 0.        , 0.        , 0.00421847, 0.        ,\n",
       "        0.        , 0.00421847, 0.00421847, 0.        , 0.00421847,\n",
       "        0.00421847, 0.        , 0.        , 0.01265542, 0.00421847,\n",
       "        0.00843695, 0.00421847, 0.00421847, 0.        , 0.00843692,\n",
       "        0.00421847, 0.        , 0.00843695, 0.        , 0.01265542,\n",
       "        0.01265542, 0.01265538, 0.01265542, 0.01265542, 0.00843695,\n",
       "        0.00421847, 0.00421847, 0.00843695, 0.01265538, 0.00421847,\n",
       "        0.00421847, 0.00421847, 0.00421847, 0.        , 0.00421847,\n",
       "        0.00421847, 0.0168739 , 0.02109233, 0.0168739 , 0.01265542,\n",
       "        0.02952927, 0.0168739 , 0.00843695, 0.02109237, 0.02109233,\n",
       "        0.02109237, 0.03374779, 0.01687388, 0.01265541, 0.02952932,\n",
       "        0.02531082, 0.01265542, 0.02952929, 0.0295293 , 0.02531083,\n",
       "        0.04640319, 0.05905861, 0.03374777, 0.02531083, 0.04640319,\n",
       "        0.06749555, 0.04218472, 0.0295293 , 0.05484014, 0.04640319,\n",
       "        0.00843694, 0.03796623, 0.05062166, 0.02531083, 0.02109237,\n",
       "        0.02531082, 0.01265541, 0.02952932, 0.03374776, 0.03374779,\n",
       "        0.0168739 , 0.0126554 , 0.05062169, 0.01265542, 0.00843693,\n",
       "        0.02531084, 0.02531084, 0.02531084, 0.02109233, 0.02109237,\n",
       "        0.02531084, 0.00843693, 0.00421847, 0.00843695, 0.02109237,\n",
       "        0.0168739 , 0.01265542, 0.00421846, 0.00421847, 0.00421847,\n",
       "        0.00421847, 0.00421847, 0.02109237, 0.00421847, 0.00421846,\n",
       "        0.00843695, 0.00843695, 0.00421847, 0.00843695, 0.        ,\n",
       "        0.01265542, 0.01265538, 0.00843695, 0.        , 0.00421847,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00421847, 0.        , 0.00421847,\n",
       "        0.        , 0.        , 0.00421847, 0.00421847, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00421847, 0.        , 0.        , 0.00843695,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.00421844]),\n",
       " array([-47.34014   , -46.79141   , -46.242676  , -45.693943  ,\n",
       "        -45.14521   , -44.596478  , -44.047745  , -43.499012  ,\n",
       "        -42.950275  , -42.401543  , -41.85281   , -41.304077  ,\n",
       "        -40.755344  , -40.20661   , -39.65788   , -39.109146  ,\n",
       "        -38.560413  , -38.01168   , -37.462948  , -36.914215  ,\n",
       "        -36.365482  , -35.81675   , -35.268013  , -34.71928   ,\n",
       "        -34.170547  , -33.621815  , -33.073082  , -32.52435   ,\n",
       "        -31.975616  , -31.426884  , -30.87815   , -30.329418  ,\n",
       "        -29.780685  , -29.23195   , -28.683218  , -28.134485  ,\n",
       "        -27.585752  , -27.03702   , -26.488287  , -25.939554  ,\n",
       "        -25.39082   , -24.842087  , -24.293354  , -23.744621  ,\n",
       "        -23.195889  , -22.647156  , -22.098423  , -21.549688  ,\n",
       "        -21.000956  , -20.452223  , -19.90349   , -19.354757  ,\n",
       "        -18.806025  , -18.257292  , -17.708557  , -17.159824  ,\n",
       "        -16.611092  , -16.062359  , -15.513626  , -14.964892  ,\n",
       "        -14.41616   , -13.867427  , -13.318694  , -12.76996   ,\n",
       "        -12.221228  , -11.672495  , -11.123761  , -10.575028  ,\n",
       "        -10.026296  ,  -9.477563  ,  -8.928829  ,  -8.380096  ,\n",
       "         -7.8313637 ,  -7.2826304 ,  -6.733897  ,  -6.1851645 ,\n",
       "         -5.636431  ,  -5.0876985 ,  -4.538965  ,  -3.9902322 ,\n",
       "         -3.4414992 ,  -2.8927662 ,  -2.3440332 ,  -1.7953001 ,\n",
       "         -1.2465671 ,  -0.69783413,  -0.14910108,   0.39963195,\n",
       "          0.948365  ,   1.497098  ,   2.045831  ,   2.594564  ,\n",
       "          3.1432972 ,   3.6920302 ,   4.240763  ,   4.789496  ,\n",
       "          5.338229  ,   5.8869624 ,   6.435695  ,   6.9844284 ,\n",
       "          7.533161  ,   8.081894  ,   8.630628  ,   9.17936   ,\n",
       "          9.728093  ,  10.276827  ,  10.82556   ,  11.374292  ,\n",
       "         11.923025  ,  12.471759  ,  13.020492  ,  13.569224  ,\n",
       "         14.117958  ,  14.666691  ,  15.215424  ,  15.764156  ,\n",
       "         16.31289   ,  16.861622  ,  17.410357  ,  17.95909   ,\n",
       "         18.507822  ,  19.056555  ,  19.605288  ,  20.15402   ,\n",
       "         20.702753  ,  21.251488  ,  21.80022   ,  22.348953  ,\n",
       "         22.897686  ,  23.446419  ,  23.995152  ,  24.543884  ,\n",
       "         25.092619  ,  25.641352  ,  26.190084  ,  26.738817  ,\n",
       "         27.28755   ,  27.836283  ,  28.385015  ,  28.93375   ,\n",
       "         29.482483  ,  30.031216  ,  30.579948  ,  31.128681  ,\n",
       "         31.677414  ,  32.226147  ,  32.77488   ,  33.323612  ,\n",
       "         33.872345  ,  34.421078  ,  34.969814  ,  35.518547  ,\n",
       "         36.06728   ,  36.616013  ,  37.164745  ,  37.713478  ,\n",
       "         38.26221   ,  38.810944  ,  39.359676  ,  39.90841   ,\n",
       "         40.45714   ,  41.005875  ,  41.554607  ,  42.10334   ,\n",
       "         42.652077  ,  43.20081   ,  43.749542  ,  44.298275  ,\n",
       "         44.847008  ,  45.39574   ,  45.944473  ,  46.493206  ,\n",
       "         47.04194   ,  47.59067   ,  48.139404  ,  48.688137  ,\n",
       "         49.23687   ,  49.785603  ,  50.33434   ,  50.88307   ,\n",
       "         51.431805  ,  51.980537  ,  52.52927   ,  53.078003  ,\n",
       "         53.626736  ,  54.17547   ,  54.7242    ,  55.272934  ,\n",
       "         55.821667  ,  56.3704    ,  56.919132  ,  57.467865  ,\n",
       "         58.0166    ,  58.565334  ,  59.114067  ,  59.6628    ,\n",
       "         60.211533  ,  60.760265  ,  61.309     ,  61.85773   ,\n",
       "         62.406464  ,  62.955196  ,  63.50393   ,  64.052666  ,\n",
       "         64.601395  ,  65.15013   ,  65.69886   ,  66.2476    ,\n",
       "         66.796326  ,  67.34506   ,  67.89379   ,  68.44253   ,\n",
       "         68.99126   ,  69.53999   ,  70.08873   ,  70.63746   ,\n",
       "         71.186195  ,  71.734924  ,  72.28366   ,  72.83239   ,\n",
       "         73.38113   ,  73.929855  ,  74.47859   ,  75.02732   ,\n",
       "         75.57606   ,  76.12479   ,  76.67352   ,  77.22225   ,\n",
       "         77.77099   ,  78.319725  ,  78.868454  ,  79.41719   ,\n",
       "         79.96592   ,  80.514656  ,  81.063385  ,  81.61212   ,\n",
       "         82.16085   ,  82.70959   ,  83.258316  ,  83.80705   ,\n",
       "         84.35578   ,  84.90452   ,  85.453255  ,  86.00198   ,\n",
       "         86.55072   ,  87.09945   ,  87.648186  ,  88.196915  ,\n",
       "         88.74565   ,  89.29438   ,  89.84312   ,  90.391846  ,\n",
       "         90.94058   ,  91.48931   ,  92.03805   ,  92.58678   ,\n",
       "         93.13551   ], dtype=float32),\n",
       " <BarContainer object of 256 artists>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "left = qmodel.stage0.rbr_reparam.weight_param.frac_bit.cpu().type(torch.int8)\n",
    "\n",
    "f_weight = qmodel.stage0.rbr_reparam.weight.detach().cpu().numpy()\n",
    "# plot_weight_distribution(qmodel, bitwidth=32) \n",
    "# sample_fweight = weight[0, :, :, :].detach().cpu().numpy().flatten()\n",
    "\n",
    "# i_weight = (qmodel.stage0.rbr_reparam.weight * torch.pow(2, left)).detach().cpu().numpy().astype(np.int8)\n",
    "sample_iweight = (qmodel.stage0.rbr_reparam.weight.detach().cpu().numpy())* (1 << left.cpu().numpy()).astype(np.int8)\n",
    "plt.hist(f_weight.flatten(), bins=256, density=True, color='red', alpha=0.5, edgecolor='black')\n",
    "plt.hist(sample_iweight.flatten(), bins=256, density=True, color='blue', alpha=0.5, edgecolor='black')\n",
    "\n",
    "# plot_weight_distribution(qmodel, bitwidth=8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
