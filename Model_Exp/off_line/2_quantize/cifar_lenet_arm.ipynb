{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import argparse\n",
    "from torchsummary import summary\n",
    "import os\n",
    "from utils.dataloaders import get_dataloader, get_subnet_dataloader\n",
    "from utils.train_eval import evaluate\n",
    "from utils.functions import reconstruction_model\n",
    "from utils.io import load_weights\n",
    "\n",
    "from utils.train_eval import get_accuracy\n",
    "from utils.utils import count_net_flops\n",
    "\n",
    "from bn_fold import bn_fold, fuse_conv_bn\n",
    "from torch import nn\n",
    "from fxpmath import Fxp\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = \"./weights/lenet_cifar10_cmsis.pth\"\n",
    "image_size = 32\n",
    "workers = 4\n",
    "batch_size = 50\n",
    "from models import LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (quant): QuantStub()\n",
      "  (dequant): DeQuantStub()\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU()\n",
      "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU()\n",
      "  (pool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU()\n",
      "  (pool3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         QuantStub-1            [-1, 3, 32, 32]               0\n",
      "            Conv2d-2           [-1, 32, 32, 32]           2,432\n",
      "       BatchNorm2d-3           [-1, 32, 32, 32]              64\n",
      "              ReLU-4           [-1, 32, 32, 32]               0\n",
      "         MaxPool2d-5           [-1, 32, 15, 15]               0\n",
      "            Conv2d-6           [-1, 32, 15, 15]          25,632\n",
      "       BatchNorm2d-7           [-1, 32, 15, 15]              64\n",
      "              ReLU-8           [-1, 32, 15, 15]               0\n",
      "         MaxPool2d-9             [-1, 32, 8, 8]               0\n",
      "           Conv2d-10             [-1, 64, 8, 8]          51,264\n",
      "      BatchNorm2d-11             [-1, 64, 8, 8]             128\n",
      "             ReLU-12             [-1, 64, 8, 8]               0\n",
      "        MaxPool2d-13             [-1, 64, 4, 4]               0\n",
      "          Flatten-14                 [-1, 1024]               0\n",
      "           Linear-15                   [-1, 10]          10,250\n",
      "      DeQuantStub-16                   [-1, 10]               0\n",
      "================================================================\n",
      "Total params: 89,834\n",
      "Trainable params: 89,834\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 1.12\n",
      "Params size (MB): 0.34\n",
      "Estimated Total Size (MB): 1.47\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = LeNet(num_channels=3, num_classes=10, model='cmsis')\n",
    "print(model)\n",
    "summary(model, (3, 32, 32), device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet(\n",
      "  (quant): QuantStub()\n",
      "  (dequant): DeQuantStub()\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu1): ReLU()\n",
      "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu2): ReLU()\n",
      "  (pool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
      "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu3): ReLU()\n",
      "  (pool3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=1024, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = load_weights(model, model_ckpt)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> loading cifar10 data...\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "flatten_model = reconstruction_model(model, device)\n",
    "def get_cifar10_loader():\n",
    "    print('=> loading cifar10 data...')\n",
    "    normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "    train_dataset = torchvision.datasets.CIFAR10(\n",
    "            root='E:/2_Quantization/torch2cmsis/examples/cifar/data/data_cifar10',\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transforms.Compose([\n",
    "            transforms.RandomCrop(32, padding=4),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "            ]))\n",
    "    trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "    test_dataset = torchvision.datasets.CIFAR10(\n",
    "            root='E:/2_Quantization/torch2cmsis/examples/cifar/data/data_cifar10',\n",
    "            train=False,\n",
    "            download=True,\n",
    "            transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "            ]))\n",
    "    testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    return trainloader, testloader\n",
    "trainloader, testloader = get_cifar10_loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before accuracy: 85.03% MAC+BN=11,504,640\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")    \n",
    "\n",
    "print(f\"Before accuracy: {get_accuracy(model.to(device), testloader):.2f}%\",\n",
    "        f\"MAC+BN={count_net_flops(model, (1, 3, image_size, image_size), True):,}\")\n",
    "# model = fuse_conv_bn(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (quant): QuantStub()\n",
       "  (dequant): DeQuantStub()\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu1): ReLU()\n",
       "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu2): ReLU()\n",
       "  (pool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "  (bn3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu3): ReLU()\n",
       "  (pool3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hci-lab01\\.conda\\envs\\lab\\lib\\site-packages\\torch\\ao\\quantization\\observer.py:214: UserWarning: Please use quant_min and quant_max to specify the range for observers.                     reduce_range will be deprecated in a future release of PyTorch.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.quantization import get_default_qconfig, quantize_dynamic, QConfig, HistogramObserver, prepare, fuse_modules\n",
    "# Custom quantization configuration 정의\n",
    "import math\n",
    "from torch.quantization import MinMaxObserver\n",
    "import torch\n",
    "\n",
    "\n",
    "class PowerOfTwoActivationObserver(HistogramObserver):\n",
    "    def __init__(self, bits=8, *args, **kwargs):\n",
    "        super(PowerOfTwoActivationObserver, self).__init__(*args, **kwargs)\n",
    "        self.bits = bits\n",
    "        self.quant_min = 0\n",
    "        self.quant_max = 2 ** bits - 1\n",
    "        self.dtype = torch.qint8  # 추가: dtype을 torch.quint8로 설정\n",
    "        self.register_buffer('scale', torch.tensor(1.0))\n",
    "        self.register_buffer('zero_point', torch.tensor(0))\n",
    "\n",
    "    def calculate_qparams(self):\n",
    "        min_val, max_val = self.min_val, self.max_val\n",
    "        if min_val == max_val:\n",
    "            scale = 1.0\n",
    "            zero_point = 0\n",
    "        else:\n",
    "            max_val = max(abs(min_val), abs(max_val))\n",
    "            scale = max_val / ((2 ** self.bits) - 1)\n",
    "            scale_pow2 = 2 ** torch.floor(torch.log2(scale))\n",
    "            zero_point = 0\n",
    "\n",
    "        self.scale.copy_(scale_pow2)\n",
    "        self.zero_point.copy_(zero_point)\n",
    "        return self.scale, self.zero_point\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.min_val = min(self.min_val, x.min())\n",
    "        self.max_val = max(self.max_val, x.max())\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return \"min_val={}, max_val={}, scale={}, zero_point={}, bits={}\".format(\n",
    "            self.min_val, self.max_val, self.scale, self.zero_point, self.bits\n",
    "        )\n",
    "class PowerOfTwoWeightObserver(HistogramObserver):\n",
    "    def __init__(self, bits=8, *args, **kwargs):\n",
    "        super(PowerOfTwoWeightObserver, self).__init__(*args, **kwargs)\n",
    "        self.bits = bits\n",
    "        self.dtype = torch.qint8  # 추가: dtype을 torch.quint8로 설정\n",
    "\n",
    "        self.quant_min = -2 ** (bits - 1)\n",
    "        self.quant_max = 2 ** (bits - 1) - 1\n",
    "        self.register_buffer('scale', torch.tensor(1.0))\n",
    "        self.register_buffer('zero_point', torch.tensor(0))\n",
    "\n",
    "    def calculate_qparams(self):\n",
    "        min_val, max_val = self.min_val, self.max_val\n",
    "        if min_val == max_val:\n",
    "            scale = 1.0\n",
    "            zero_point = 0\n",
    "        else:\n",
    "            max_val = max(abs(min_val), abs(max_val))\n",
    "            scale = max_val / (2 ** (self.bits - 1) - 1)\n",
    "            scale_pow2 = 2 ** torch.floor(torch.log2(scale))\n",
    "            zero_point = 0\n",
    "\n",
    "        self.scale.copy_(scale_pow2)\n",
    "        self.zero_point.copy_(zero_point)\n",
    "        return self.scale, self.zero_point\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.min_val = min(self.min_val, x.min())\n",
    "        self.max_val = max(self.max_val, x.max())\n",
    "        return x\n",
    "\n",
    "    def extra_repr(self):\n",
    "        return \"min_val={}, max_val={}, scale={}, zero_point={}, bits={}\".format(\n",
    "            self.min_val, self.max_val, self.scale, self.zero_point, self.bits\n",
    "        )\n",
    "\n",
    "backend = \"x86\"\n",
    "model.qconfig = QConfig(\n",
    "            activation=PowerOfTwoWeightObserver.with_args(bits=8, \n",
    "                                                          qscheme=torch.per_tensor_symmetric,\n",
    "                                                          dtype=torch.qint8,\n",
    "                                                          reduce_range=True),\n",
    "            weight=PowerOfTwoWeightObserver.with_args(bits=8,\n",
    "                                              qscheme=torch.per_tensor_symmetric,\n",
    "                                              dtype=torch.qint8, \n",
    "                                              reduce_range=True)\n",
    "            )\n",
    "\n",
    "# model.qconfig = torch.quantization.QConfig(\n",
    "#     activation=HistogramObserver.with_args(dtype=torch.qint8, \n",
    "#                                            qscheme=torch.per_tensor_symmetric),\n",
    "#     weight=HistogramObserver.with_args(dtype=torch.qint8,\n",
    "#                                         qscheme=torch.per_tensor_symmetric)\n",
    "# )\n",
    "\"\"\"\n",
    "LeNet(\n",
    "  (conv1): Conv2d(3, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "  (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  (relu1): ReLU()\n",
    "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "  (conv2): Conv2d(32, 16, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "  (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  (relu2): ReLU()\n",
    "  (pool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
    "  (conv3): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
    "  (bn3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "  (relu3): ReLU()\n",
    "  (pool3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
    "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
    "  (fc1): Linear(in_features=512, out_features=10, bias=True)\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "fuse_modules(model, [['conv1', 'bn1', 'relu1'],\n",
    "                     ['conv2', 'bn2', 'relu2'],\n",
    "                     ['conv3', 'bn3','relu3']], inplace=True)\n",
    "\n",
    "\n",
    "qmodel = prepare(model, inplace=False)\n",
    "# model.qconfig = torch.quantization.get_default_qconfig(backend)\n",
    "# torch.backends.quantized.engine = backend\n",
    "# model_static_quantized = torch.quantization.prepare(model, inplace=False)\n",
    "# model_static_quantized = torch.quantization.convert(model_static_quantized, inplace=False)\n",
    "# model.qconfig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LeNet(\n",
       "  (quant): Quantize(scale=tensor([0.0156], device='cuda:0'), zero_point=tensor([0], device='cuda:0'), dtype=torch.qint8)\n",
       "  (dequant): DeQuantize()\n",
       "  (conv1): QuantizedConvReLU2d(3, 32, kernel_size=(5, 5), stride=(1, 1), scale=0.125, zero_point=0, padding=(2, 2))\n",
       "  (bn1): Identity()\n",
       "  (relu1): Identity()\n",
       "  (pool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): QuantizedConvReLU2d(32, 32, kernel_size=(5, 5), stride=(1, 1), scale=0.0625, zero_point=0, padding=(2, 2))\n",
       "  (bn2): Identity()\n",
       "  (relu2): Identity()\n",
       "  (pool2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (conv3): QuantizedConvReLU2d(32, 64, kernel_size=(5, 5), stride=(1, 1), scale=0.0625, zero_point=0, padding=(2, 2))\n",
       "  (bn3): Identity()\n",
       "  (relu3): Identity()\n",
       "  (pool3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (fc1): QuantizedLinear(in_features=1024, out_features=10, scale=0.0625, zero_point=0, qscheme=torch.per_tensor_affine)\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "qmodel = qmodel.to(device)\n",
    "with torch.inference_mode():\n",
    "    for img, label in trainloader:\n",
    "        img = img.to(device)\n",
    "        label = label.to(device)\n",
    "        if cnt > 10:\n",
    "            break\n",
    "        qmodel(img)\n",
    "    \n",
    "qmodel = torch.quantization.convert(qmodel, inplace=True)\n",
    "qmodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82.79000091552734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "# print(get_accuracy(qmodel, testloader), count_net_flops(model, (1, 3, image_size, image_size)))\n",
    "print(get_accuracy(qmodel, testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "361.42 KB\n",
      "96.39 KB\n"
     ]
    }
   ],
   "source": [
    "def print_model_size(mdl):\n",
    "    torch.save(mdl.state_dict(), \"tmp.pt\")\n",
    "    print(\"%.2f KB\" %(os.path.getsize(\"tmp.pt\")/1e3))\n",
    "    os.remove('tmp.pt')\n",
    "\n",
    "print_model_size(model)\n",
    "print_model_size(qmodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
